This release is the official GA release for .NET Core support for the Couchbase .NET SDK! .NET Core is the latest incarnation of the .NET framework and its described as “.NET Core is a blazing fast, lightweight and modular platform for creating web applications and services that run on Windows, Linux and Mac”

Wait a minute…read that again: “.NET Core is a blazing fast, lightweight and modular platform for creating web applications and services that run on Windows, Linux and Mac“. Microsoft .NET applications running on OSX and Linux? What kind of bizzaro world are we living in? It’s the “New” Microsoft for sure!

In this blog post, I’ll go over what is in the 2.4.0 release, changes to packaging (NuGet), and what version of .NET the SDK supports. We’ll also demonstrate some of the new features such as Datastructures.

What’s in this release?

2.4.0 is a large release with over 30 commits. When you consider that we released 3 Developer Previews leading up to 2.4.0, there are actually many, many more commits leading up to this release over the last 6 months. Here is an overview of some of the more impressive features – you can see all of the commits in the “Release Notes” section below:

.NET Core Support

Of course the most significant feature of 2.4.0 is .NET Core support, which from the opening paragraph, means you can now develop on Mac OS or Windows and deploy to Linux (or vice-versa, but the tooling is a bit immature still). This is great stuff and a major change for the traditional Windows developer.

If you’re unaware of .NET Core, you can read up more about it over on the .NET Core website. One cool thing about it is that it’s open source (Apache 2.0) and source is all available on Github.

The Couchbase SDK specifically supports the netstandard1.5 or greater. We tested the SDK using 1.0.0-preview2-1-003177 of the Command Line Tools.

Packaging changes

Just like the three developer previews, the NuGet package will contain binaries for both the .NET Full Framework (targeting .NET 4.5 or greater), but also for .NET Core (targeting .NET Core 1.1). Depending on the target project you are including the dependency for, the correct binaries will be used.

So, if your Visual Studio project is a .NET Full Framework application greater than or equal to 4.5, you’ll get the binaries for the full framework version of .NET. Likewise, if your application is a .NET Core application, then the .NET Core version of the binaries will be used. There should be nothing you have to do to enable this.

The older .NET 4.5 version of the packages will no longer be released; 2.3.11 is the last supported release of the 2.3.X series.

MS Logging for Core

For .NET Core we decided to change from using Common.Logging to MS Logging mainly because no 3rd party (log4net for example) have stable support for .NET Core at this time.

Additionally, by moving from Common.Logging  to MS Logging we have removed one more 3rd party dependency – which is always nice. Not that Common.Logging wasn’t sufficient, but it makes more sense to use a dependency from Microsoft.

Here is an example of configuring the 2.4.0 client targeting .NET Core and using NLog:

First add the dependencies to the project.json:
{
  "version": "1.0.0-*",
  "buildOptions": {
    "emitEntryPoint": true,
    "copyToOutput": {
      "include": [ "config.json", "nlog.config" ]
    }
  },

  "dependencies": {
    "CouchbaseNetClient": "2.4.0-dp6",
    "NLog.Extensions.Logging": "1.0.0-rtm-beta1",
    "Microsoft.NETCore.App": {
      "type": "platform",
      "version": "1.0.1"
    },
    "Microsoft.Extensions.Logging.Debug": "1.1.0",
    "Microsoft.Extensions.Logging": "1.1.0"
  },

  "frameworks": {
    "netcoreapp1.0": {
      "imports": "dnxcore50"
    }
  }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
	
{
  "version": "1.0.0-*",
  "buildOptions": {
    "emitEntryPoint": true,
    "copyToOutput": {
      "include": [ "config.json", "nlog.config" ]
    }
  },
 
  "dependencies": {
    "CouchbaseNetClient": "2.4.0-dp6",
    "NLog.Extensions.Logging": "1.0.0-rtm-beta1",
    "Microsoft.NETCore.App": {
      "type": "platform",
      "version": "1.0.1"
    },
    "Microsoft.Extensions.Logging.Debug": "1.1.0",
    "Microsoft.Extensions.Logging": "1.1.0"
  },
 
  "frameworks": {
    "netcoreapp1.0": {
      "imports": "dnxcore50"
    }
  }
}

Then, add a nlog.config file to your project with the following contents:
<?xml version="1.0" encoding="utf-8" ?>
<nlog xmlns="http://www.nlog-project.org/schemas/NLog.xsd"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
      autoReload="true"
      internalLogLevel="Debug"
      internalLogFile="c:\temp\internal-nlog.txt">

  <!-- define various log targets -->
  <targets>
    <!-- write logs to file -->
    <target xsi:type="File" name="allfile" fileName="c:\temp\nlog-all-${shortdate}.log"
                layout="${longdate}|${event-properties:item=EventId.Id}|${logger}|${uppercase:${level}}|${message} ${exception}" />

    <target xsi:type="Null" name="blackhole" />
  </targets>

  <rules>
    <!--All logs, including from Microsoft-->
    <logger name="*" minlevel="Trace" writeTo="allfile" />
  </rules>
</nlog>
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
	
<?xml version="1.0" encoding="utf-8" ?>
<nlog xmlns="http://www.nlog-project.org/schemas/NLog.xsd"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
      autoReload="true"
      internalLogLevel="Debug"
      internalLogFile="c:\temp\internal-nlog.txt">
 
  <!-- define various log targets -->
  <targets>
    <!-- write logs to file -->
    <target xsi:type="File" name="allfile" fileName="c:\temp\nlog-all-${shortdate}.log"
                layout="${longdate}|${event-properties:item=EventId.Id}|${logger}|${uppercase:${level}}|${message} ${exception}" />
 
    <target xsi:type="Null" name="blackhole" />
  </targets>
 
  <rules>
    <!--All logs, including from Microsoft-->
    <logger name="*" minlevel="Trace" writeTo="allfile" />
  </rules>
</nlog>

Finally, add the code to configure the Couchbase SDK for logging:

using Couchbase;
using Couchbase.Logging;
using Microsoft.Extensions.Logging;
using NLog.Extensions.Logging;

namespace ConsoleApp2
{
    public class Program
    {
        public static void Main(string[] args)
        {
            var factory = new LoggerFactory();
            factory.AddDebug();
            factory.AddNLog();
            factory.ConfigureNLog("nlog.config");

            //configure logging on the couchbase client
            var config = new ClientConfiguration
            {
                LoggerFactory = factory
            };

            var cluster = new Cluster(config);
            //use the couchbase client
        }
    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
	
using Couchbase;
using Couchbase.Logging;
using Microsoft.Extensions.Logging;
using NLog.Extensions.Logging;
 
namespace ConsoleApp2
{
    public class Program
    {
        public static void Main(string[] args)
        {
            var factory = new LoggerFactory();
            factory.AddDebug();
            factory.AddNLog();
            factory.ConfigureNLog("nlog.config");
 
            //configure logging on the couchbase client
            var config = new ClientConfiguration
            {
                LoggerFactory = factory
            };
 
            var cluster = new Cluster(config);
            //use the couchbase client
        }
    }
}

Note that the project.json has a copyToOutput.include  value for nlog.config . This is required so the tooling will copy that file to the output directory when built.

Now for the .NET 4.5 Full Framework binaries, the dependency on Common.Logging remains and any existing logging configuration should work as it always has.

Datastructures

Datastructures are a new way of working with Couchbase documents as if they are a common Computer Science data structures such as lists, queues, dictionaries or sets. There are two implementations in the SDK; one as a series of methods on CouchbaseBucket  which provide functionality for common data structure operations and another as implementations of the interfaces within System.Collections.Generics . Here is a description of each Datastructure class found in the SDK:

    CouchbaseDictionary<TKey, TValue> : Represents a collection of keys and values stored within a Couchbase Document.
    CouchbaseList<T> : Represents a collection of objects, stored in Couchbase server, that can be individually accessed by index.
    CouchbaseQueue<T> : Provides a persistent Couchbase data structure with FIFO behavior.
    CouchbaseSet<T> : Provides a Couchbase persisted set, which is a collection of objects with no duplicates.

All of these classes are found in the Couchbase.Collections  namespace. Here is an example of using a CouchbaseQueue<T> :
var queue = new CouchbaseQueue<Poco>(_bucket, "somekey");
queue.Enqueue(new Poco { Name = "pcoco1" });
queue.Enqueue(new Poco { Name = "pcoco2" });
queue.Enqueue(new Poco { Name = "pcoco3" });

var item = queue.Dequeue();
Assert.AreEqual("pcoco1", item.Name);
1
2
3
4
5
6
7
	
var queue = new CouchbaseQueue<Poco>(_bucket, "somekey");
queue.Enqueue(new Poco { Name = "pcoco1" });
queue.Enqueue(new Poco { Name = "pcoco2" });
queue.Enqueue(new Poco { Name = "pcoco3" });
 
var item = queue.Dequeue();
Assert.AreEqual("pcoco1", item.Name);

Multiplexing IO

The Couchbase SDK has used connection pooling in the past to allow high throughput and scale at the cost of latency and resource utilization. In Couchbase 2.2.4 we introduced a better IO model call Multiplexing IO or MUX-IO, which the client could be configured to use (the default was pooled connections).

In 2.4.0 we are making MUX-IO the default IO model and making connection pooling optional. What this means to you is that some connection pooling properties in your configuration may still be used SDK. For example:

    PoolConfiguration.MaxSize  is still used but should be relatively small values – e.g. 5-10
    PoolConfiguration.MinSize should be 0 or 1

To disable MUX-IO it’s simply a matter of setting the  ClientConfiguration.UseConnectionPoolingto true (the default is false) to use connection pooling:
var clientConfig = new ClientConfiguration{
    UseConnectionPooling = false
 };
var cluster = new Cluster(clientConfig);
 
//open buckets and use the client
1
2
3
4
5
6
	
var clientConfig = new ClientConfiguration{
    UseConnectionPooling = false
 };
var cluster = new Cluster(clientConfig);
 
//open buckets and use the client

Streaming N1QL and Views

Streaming N1QL and Views are a performance optimization in certain cases where the amount of data retrieved is large. To understand why, let’s consider how non-streaming queries work:

    A request is dispatched to the server.
    The server does it’s processing and returns back the results as a stream after processing the entire response.
    The client buffers the entire stream and then de-serializes the stream into a collection of type “T”, where T is the POCO that each result is mapped to.
    The server returns back the list to the application within its IResult

What can go wrong here? Think about very large results and that memory resources are finite: eventually you will always encounter an OutOfMemoryException ! There are other side effects as well related to Garbage Collection.

With streaming clients the process is as follows:

    A request is dispatched to the server
    The server does it’s processing and returns back the results as a stream as soon as the response headers are available.
    The client partially reads the headers and meta-data and then pauses until iteration occurs.
    When the application starts iterating over the IResult , each item is read one at a time without storing in an underlying collection.

The big benefit here is that the working set of memory will not grow as the collection grows and internally re-sized by .NET. Instead, you have a fixed working size of memory and GC can occur as soon as the read object is discarded.

To use streaming N1QL and views, all that you do is call the UseStreaming() method and pass in true to stream:
var request = new QueryRequest("SELECT * FROM `travel-sample` LIMIT 100;").UseStreaming(true);
using (var result = _bucket.Query<dynamic>(request))
{
    Console.WriteLine(result);
}
1
2
3
4
5
	
var request = new QueryRequest("SELECT * FROM `travel-sample` LIMIT 100;").UseStreaming(true);
using (var result = _bucket.Query<dynamic>(request))
{
    Console.WriteLine(result);
}

Passing in false will mean that the entire response is buffered and processed before returning.

N1QL Query Cancellation

This feature allows long running N1QL queries to be canceled before they complete using task cancellation tokens. For example:
var cancellationTokenSource = new CancellationTokenSource(TimeSpan.FromMilliseconds(5));

var result = await _bucket.QueryAsync<dynamic>(queryRequest, cancellationTokenSource.Token);
//do something with the result
1
2
3
4
	
var cancellationTokenSource = new CancellationTokenSource(TimeSpan.FromMilliseconds(5));
 
var result = await _bucket.QueryAsync<dynamic>(queryRequest, cancellationTokenSource.Token);
//do something with the result

This commit was via a community contribution from Brant Burnett of CenteredgeSoftware.com!

Important TLS/SSL Note on Linux

There is one issue on Linux that you may come across if you are using SSL: a PlatformNotSupportedException will be thrown if you have a version of libcurl installed on the server < 7.30.0. The work-around is to simply upgrade your libcurl installation on Linux to something equal to or greater than 7.30.0. You can read more about this on the Jira ticket: NCBC-1296.



https://blog.couchbase.com/introducing-couchbase-net-2-4-0-net-core-ga/




ASP.NET Core Tools to Get Started

The following video will take you from having no code to having an HTTP REST API that uses Couchbase Server, built with ASP.NET Core.

These tools are used in the video:

    Visual Studio 2017

    Couchbase Server 5.0 Community Edition (Enterprise Edition will also work)

    Couchbase .NET SDK

    ASP.NET Core 2.0

    Swagger (provided by Swashbuckle.AspNetCore)

https://blog.couchbase.com/asp-net-core-couchbase-getting-started/




The Couchbase .NET SDK enables you to interact with a Couchbase Server cluster from the .NET Framework using C#. It offers both a traditional synchronous API and an asynchronous API based on the Task-based Asynchronous Pattern (TAP).
Installing the SDK
Installing the SDK

The following sections explain in detail how to get started using each method.
Installing the Client
Installing the Client

The Couchbase .NET SDK is compatable with both Microsoft .NET Framework 4.5 or and Microsoft .NET Core runtimes. Microsoft Visual Studio 2013 or later is assumed in this guide, though you should use 2015 or later if possible. Add the Couchbase .NET SDK to your Visual Studio solution using one of the following methods:

    Using NuGet (recommended method)
    Downloading and referencing the binaries
    Building from source yourself

Information on new features, fixes, known issues as well as information on how to install older release versions is in the release notes.

The following sections explain in detail how to get started using each method.
Using NuGet
Using NuGet

For every release, we package the binaries and store the latest version in NuGet. If you are not familiar with NuGet, it’s the official and most widely supported package manager for Microsoft Visual Studio and .NET in general. NuGet is a centralized repository for package authors and consumers, and it also defines a suite of tools for authoring and consuming packages.

Using Visual Studio 2013 or later, follow these steps to get started with the Couchbase .NET SDK:

    From the IDE, right-click the project you want to add the dependency to.
    In the context menu, click Manage NuGet Packages. The NuGet package manager modal dialog opens.
    From the Tree View menu on the left, select Online > nuget.org.
    In the search box at the top right-hand side of the dialog, type CouchbaseNetClient and then press enter on your keyboard.
    In the search results, select the CouchbaseNetClient package and then click Install.

That’s it! NuGet will pull in all required dependencies and reference them. You're ready to start coding!

As an alternative to using the Visual Studio IDE, you can include the binaries by using the Package Manager Console. The main advantage of using the Package Manager Console is that the NuGet Dialog by default always installs the latest version of the package published to NuGet.org, however the console allows you to define the version of the package you want to include. For users targeting older builds of the SDK, using the Package Manager Console is the best option.

To use the Package Manager Console to include the SDK in your project:

    From the Visual Studio menu bar, click Tools.
    Select NuGet Package Manager > Package Manager Console.
    In the console, enter the package installation command:
        To install the latest version:

        Install-Package CouchbaseNetClient

        To install a specific version, include the version parameter. For example:

        Install-Package CouchbaseNetClient -Version 2.0.0 -Pre

Downloading and referencing the binaries
Downloading and referencing the binaries

If you do not want to use NuGet to include the Couchbase .NET SDK in your project, you can download and reference the binaries directly. If you chose this route, you’ll also be responsible for including and resolving dependencies used internally by the SDK.

To download and reference the binaries directly:

    Download the version of the SDK you want to install - Releases
    In Visual Studio, right-click the project you want to include the SDK in and then click Add.
    Click Reference to open the Reference Manager.
    On the left side, click Browse and select the binaries you downloaded.
    Click OK.

After you have referenced the Couchbase .NET SDK binaries, you need to locate and reference the dependencies it uses in a similar fashion.

.NET Framework dependencies are:

    Apache Common Infrastructure Libraries for .NET v3.3.1: http://net-commons.github.io/common-logging/
    Json.NET v9.0.1: https://github.com/JamesNK/Newtonsoft.Json/releases

.NET Core dependencies are:

    Microsoft.Extensions.Logging v1.0.1: https://github.com/aspnet/Logging
    Json.NET v9.0.1: https://github.com/JamesNK/Newtonsoft.Json/releases

Other versions might not be compatible with the current SDK version.
Building from source
Building from source

If none of the other installation options suffice or if you want to debug the source or perhaps contribute, building directly from the source is the best option for you. All source is located on GitHub.
Note:

The software provided via NuGet and S3 are the official releases that have been through a rigorous testing process. Code on GitHub that is not tagged as an official release is still in development.

To build the .NET SDK from source:

    (Optional) Fork the GitHub repository: https://github.com/couchbase/couchbase-net-client/fork
    Using a Git console, enter the command to clone the repository:

    git clone https://github.com/couchbase/couchbase-net-client.git

    Enter the command to retrieve the latest code from GitHub:

    git pull origin master

    Navigate to the directory that the source was cloned to and open the solution.
    Build the solution.

After you have successfully built the source, it’s then just a matter of referencing the binaries (.DLL files) from your consuming project.
Hello Couchbase
Hello Couchbase

This tutorial creates a simple console application using Visual Studio that illustrates the most basic usage of the Couchbase .NET SDK.

To begin, open Visual Studio and create a new Console Application Project called Couchbase.HelloCouchbase:

This creates a simple executable with a main() method that you can use to try reading and writing from a Couchbase Cluster.

Next, use the NuGet Package Manager to reference the Couchbase .NET SDK and its dependencies:

At this point, you should be ready to go. Add a Cluster object, which represents a factory and resource manager for Couchbase buckets. This is added to the Program.cs file that was added automatically by Visual Studio when the project was created:
Creating the Cluster and Bucket

var cluster = new Cluster(new ClientConfiguration 
{ 
    Servers = new List<Uri> { new Uri("http://10.112.170.101") }
});

var authenticator = new PasswordAuthenticator("username", "password");
cluster.Authenticate(authenticator);
var bucket = cluster.OpenBucket("bucketname");

The instance of Couchbase Server on which the bucket resides is specified as a URI. The bucket itself is referenced by name. To connect to a Couchbase bucket, you must use Couchbase Role-Based Access Control (RBAC). This is fully described in the section Authorization. A username and password for the current user must be specified. Following successful authentication, the bucket is opened.

Once you have connected to a Couchbase bucket, you can create a document and add it to the database:
Storing and Getting a document

using (var bucket = cluster.OpenBucket())
{
	var document = new Document<dynamic>
	{
		Id = "Hello",
		Content = new
		{
			name = "Couchbase"
		}
	};

	var upsert = bucket.Upsert(document);
	if (upsert.Success)
		{
			var get = bucket.GetDocument<dynamic>(document.Id);
			document = get.Document;
			var msg = string.Format("{0} {1}!", document.Id, document.Content.name);
			Console.WriteLine(msg);
		}
	Console.Read();
}

First, the code creates a new Document object, types it as dynamic and provides an Id value. Then, it creates the actual value that will be stored as JSON in Couchbase and assigns it to the Content property. After the Document object is created, it uses the Upsert() method to store it into the database. Finally, it checks whether the operation was successful and if it is, does a GetDocument() operation to retrieve the document and formats a string with the Id of the document and the Name property from the Content field (the actual JSON document).

If you build and run this from Visual Studio, you should see the following message output:

Hello Couchbase!

Congratulations, you have successfully created the Hello Couchbase Tutorial! The full source can be found on GitHub.
API Reference
API Reference
The API reference is generated for each release and can be found here.
Contributing
Contributing

Couchbase welcomes community contributions to the .NET SDK. The .NET SDK source code is available on GitHub.


https://developer.couchbase.com/documentation/server/current/sdk/dotnet/start-using-sdk.html

Couchbase recently announced the new release of .NET 2.4.0 SDK. The SDK is the official GA release for .NET Core support for the Couchbase .NET SDK.

One of the most significant features of 2.4.0 is .NET Core support.

.NET Core is the open-source version of Microsoft’s .NET Framework that supports all Mac, Windows, and Linux platforms.

Some key upgrades in this version:

    Packaging will now contain both .NET Framework and .NET Core 1.1 binaries
    Common.Logging replaced with MS Logging for Core
    Datastructures are a new way of working with Couchbase documents such as lists, queues, dictionaries or sets.
    Introduced a better IO model call Multiplexing IO or MUX-IO, which the client could be configured to use (the default was pooled connections).
    Streaming N1QL and Views are a performance optimization in certain cases where the amount of data retrieved is large.
http://www.c-sharpcorner.com/news/couchbase-now-supports-net-core




In many of my blog posts and samples, I use a single Couchbase Server node. I do this because it’s easy, and much of what I demonstrate can be done with a single node. However, Couchbase Server is typically run on multiple nodes in production (sometimes 3, sometimes 3000). In order to simulate this locally, I can use some lightweight Docker containers.

While I’m at it, I’m going to show you how to get started with an ASP.NET Core website, also running on Docker.
What you need to get started

    Docker for Windows. You can use Docker for any platform, but in this sample, I’m using Windows.
    Visual Studio 2015 (or later). You don’t need Visual Studio to use ASP.NET Core or Docker, but I’m using a Visual Studio extension to make things easier.
    .NET Core VS 2015 tooling preview 2 or higher. This is .NET Core tooling for Visual Studio.
    Visual Studio Tools for Docker (preview). More VS tooling to make the job easier.

Once you have all of the above installed, make sure to turn on drive sharing in Docker. Otherwise, you will get a error like The "PrepareForLaunch" task failed unexpectedly later. (I needed to enable sharing on both C and D drive, but your setup will vary).
Enable shared drives in Docker for Windows
Setup Couchbase Server on Docker

Start by running a Couchbase Docker image. Since the ASP.NET Core site will be running within Docker, we only need to expose port 8091 (to use the Couchbase Console from a web browser at localhost:8091).

docker run -d --name db -p 8091:8091 couchbase

I named it db but you are welcome to name it whatever you’d like. I specified couchbase as the image, which is Couchbase Server 4.5.1 at the time I’m writing this.

Next, run at least one more container with Couchbase. There’s no need to map any ports for these. I’ll just create two:

docker run -d --name db2 couchbase

docker run -d --name db3 couchbase

Make note of the IP addresses of these two containers by using docker inspect db / docker inspect db2 / etc…? and looking for IPAddress in the output.

Now, point your web browser to localhost:8091 to setup the Couchbase cluster. If you’ve not done this before, you can check out this blog post on setting up Couchbase Server or you can watch this video on stepping through Couchbase Server setup.

When you setup and create a bucket (I created a bucket named ‘default’), go ahead and enable replication, since we’re going to add some more nodes.
Enable replication when creating a bucket

Go to the Server Nodes tab and click “Add Server”. Enter the IP Address of db2 and click “Add Server”. Repeat for db3 and any other nodes you’ve created. At this point, you should see a number next to “Pending Rebalance”. This means the nodes are ready to become part of the cluster.
Rebalance pending in Couchbase Console

Click ‘rebalance’. This will take a little bit of time, but when it’s done, you’ll have a Couchbase Server cluster all running within Docker. It’s important to note that even during the rebalancing operation, the cluster remains functional.
Couchbase Cluster in Docker

While you’re in the Couchbase Console, go ahead and create a primary index. Execute CREATE PRIMARY INDEX on default in the Query tab. The ASP.NET Core app will need this.
Create an ASP.NET Core app

From Visual Studio, create a new ASP.NET Core app. Or you can use the ASP.NET Core source code I’ve already prepared for this example on GitHub. It’s a very simple website with two operations: list all the gifts and add a new random(ish) gift to the list. (It’s that time of year and I’ve got gifts on my mind!)
New ASP.NET Core project in Visual Studio

Add the CouchbaseNetClient dependency with NuGet. We’ll be using the .NET Core SDK, which is currently in developer preview. Therefore, you will need to execute Install-Package CouchbaseNetClient -Pre in the Package Manager Console. If you don’t use -Pre, NuGet will attempt to install the .NET SDK instead of the .NET Core SDK.

Next, add Docker support to the project. Right-click the project, then click Add, then click “Docker Support”. This will add some Docker files to your project. If you don’t see this option, then you need to install Visual Studio Tools for Docker.
Add Docker support with Visual Studio Tools for Docker

In the ASP.NET Core app, setup the ClusterHelper to point to the Couchbase Cluster by using one or more of the IP addresses of the db/db2/db3 containers.
var client = new ClientConfiguration();
client.Servers = new List {new Uri("couchbase://172.17.0.2")};
ClusterHelper.Initialize(client);
1
2
3
	
var client = new ClientConfiguration();
client.Servers = new List {new Uri("couchbase://172.17.0.2")};
ClusterHelper.Initialize(client);

Check out the full source code on GitHub, especially HomeController.cs and Gift.cs. Here is the Index action and the GetAllGifts method it’s calling.
public IActionResult Index()
{
    var gifts = Gift.GetAllGifts();
    return View(gifts);
}

public static List GetAllGifts()
{
    var bucket = ClusterHelper.GetBucket("default");
    var query = QueryRequest.Create("SELECT g.* FROM `default` g");
    query.ScanConsistency(ScanConsistency.RequestPlus);
    return bucket.Query(query).Rows;
}
1
2
3
4
5
6
7
8
9
10
11
12
13
	
public IActionResult Index()
{
    var gifts = Gift.GetAllGifts();
    return View(gifts);
}
 
public static List GetAllGifts()
{
    var bucket = ClusterHelper.GetBucket("default");
    var query = QueryRequest.Create("SELECT g.* FROM `default` g");
    query.ScanConsistency(ScanConsistency.RequestPlus);
    return bucket.Query(query).Rows;
}

Since you have Docker tools installed, there’s a new deploy button for Docker.
Docker deploy button in Visual Studio

Click this to run your ASP.NET Core app in Docker. Note that when you first run this, it might take longer because it’s downloading the aspnetcore image from Docker Hub.

Once that container is deployed, there’s one more step. For whatever reason, the aspnetcore Docker image doesn’t attach to the ‘bridge’ Docker network. Therefore, the ASP.NET Core app can’t see the Couchbase cluster. To add ‘bridge’, run docker network connect bridge dockernetcore_dockernetcore_1 (the name of your container may vary). There might be another way to do this by changing the Dockerfile or docker-compose.yml, but I don’t know what it is (yet).

Run the ASP.NET Core app again (with Docker). The website should appear in your browser. At this point, you have 4 containers running in the Docker host together: a web server running ASP.NET Core and three Couchbase Server nodes.
ASP.NET Core website using Couchbase Server
Summary

When your site is running, and you’ve added a few gifts, go back to the Couchbase Console and open the Server Nodes tab. Take a look at the “Items” column and note the Active/Replica split. As you add gifts, note that the documents are being automatically sharded amongst the nodes, and the replicas are being stored in the other nodes.

Something else you can try for fun: turn on auto-failover (Settings ? Auto-Failover ? Enable), and then shut down one of the Couchbase nodes (docker stop db2 for instance). Then watch the Couchbase Console as the node goes down and the other nodes compenstate. Finally, bring the node back online (docker start db2), and notice that the cluster gives you some options for adding the node back in.
Options for recovering a Couchbase node

I’m pretty new at both Docker and ASP.NET Core, so if you have any tips or suggestions, I’d love to hear them. Please leave a comment or find @mgroves on Twitter.


https://blog.couchbase.com/docker-and-asp-net-core-with-couchbase-server/



https://blog.couchbase.com/distributed-session-aspnet-couchbase/


Distributed session is a way for you to store your session state outside of your ASP.NET Core application. Using Couchbase to store session state can help you when you need to scale your web site, especially if you don’t want to use sticky sessions.

You can follow along with the code samples I’ve created, available on GitHub.

Note that Couchbase.Extensions.Session is a beta release at the time of this writing.
Review of session

Session state is simply a way to store data for a particular user. Typically, a token is stored in a user cookie, and that token acts as a key to some set of data on the server side.

If you’re familiar with ASP.NET or ASP Classic, this is done using Session. All the cookie work is done behind the scenes, so you simply use Session as a dictionary to store and retrieve whatever data you want.
if(Session["IsLoggedIn"] = false)
    Session["Username"] = "matt";
1
2
	
if(Session["IsLoggedIn"] = false)
    Session["Username"] = "matt";

By default, in ASP.NET and ASP Classic, this information is stored in memory, as part of the web application process.

In ASP.NET Core, you can also opt-in to this by configuring session with AddSession.

First, in Startup.cs, in the Configure function, tell ASP.NET Core to use session:
app.UseSession();
1
	
app.UseSession();

Then, in the ConfigureServices function, use AddSession to add a session provider service.
services.AddDistributedMemoryCache();
services.AddSession();
1
2
	
services.AddDistributedMemoryCache();
services.AddSession();

(This will use the default session settings, see the ASP.NET Core documentation for more information).
Why distributed session?

However, if you are scaling out your web application with multiple web servers, you’ll have to make some decisions about session. If you continue to use in-process session, then you must configure sticky sessions (the first web server that a user hits is the one they will “stick” with for subsequent requests). This has some potential downsides (see this thread on ServerFault and this article on Microsoft’s TechNet magazine).

If you don’t want to use sticky sessions, then you can’t use the in-process session option. You’ll instead need to use a distributed session. There are a lot of options for where to put session data, but Couchbase’s memory-first architecture and flexible scaling capabilities make it a good choice.
Using distributed session in ASP.NET Core

Before you start writing code, you’ll need a Couchbase Server cluster running with a bucket (I named mine “sessionstore”). You’ll also need to create a user with Data Reader and Data Writer permission on the bucket (I also called my user “sessionstore” just to keep things simple).
Adding Couchbase.Extensions.Session

Now, open up your ASP.NET Core application in Visual Studio. (I created a new ASP.NET Core MVC app, which you can find on GitHub). Next, with NuGet, install the Couchbase.Extensions.Session library:

    Use the NuGet UI (see below), or

    Install-Package Couchbase.Extensions.Session -Version 1.0.0-beta2 with the Package manager, or

    dotnet add package Couchbase.Extensions.Session --version 1.0.0-beta2 with the dotnet command line

Couchbase Extensions with NuGet
Configuring Couchbase

To configure the session provider, you’ll be writing some code that looks familiar if you’ve been following along in this Couchbase.Extensions series.

The ConfigureServices method in Startup.cs is where you’ll be adding configuration code.

First, use AddCouchbase, which is done with the Dependency Injection extension.

After that, setup the distributed cache for Couchbase with AddDistributedCouchbaseCache, which I covered in a blog post on distributed caching.
services.AddCouchbase(opt =>
{
    opt.Servers = new List<Uri> { new Uri("http://localhost:8091") };
});

services.AddDistributedCouchbaseCache("sessionstore", "password", opt => { });
1
2
3
4
5
6
	
services.AddCouchbase(opt =>
{
    opt.Servers = new List<Uri> { new Uri("http://localhost:8091") };
});
 
services.AddDistributedCouchbaseCache("sessionstore", "password", opt => { });

Finally, configure Couchbase as a session store with AddCouchbaseSession.
services.AddCouchbaseSession(opt =>
{
    opt.CookieName = ".MyApp.Cookie";
    opt.IdleTimeout = new TimeSpan(0, 0, 20, 0);
});
1
2
3
4
5
	
services.AddCouchbaseSession(opt =>
{
    opt.CookieName = ".MyApp.Cookie";
    opt.IdleTimeout = new TimeSpan(0, 0, 20, 0);
});

You can configure the idle timeout (how long until the session expires after not being used), the cookie name, and more, if you need to. In the above example, I set the timeout to 20 minutes and the cookie name to “.MyApp.Cookie”.
Writing to a distributed session

To access Session data, you can use HttpContext.Session.

First, I want to write something to session. In an About controller action, I used the SetObject method:
public IActionResult About()
{
    HttpContext.Session.SetObject("sessionkey", new
    {
        Name = "Matt",
        Twitter = "@mgroves",
        Guid = DateTime.Now
    });

    ViewData["Message"] = "I put a value in your session. Click 'Contact' to see it.";

    return View();
}
1
2
3
4
5
6
7
8
9
10
11
12
13
	
public IActionResult About()
{
    HttpContext.Session.SetObject("sessionkey", new
    {
        Name = "Matt",
        Twitter = "@mgroves",
        Guid = DateTime.Now
    });
 
    ViewData["Message"] = "I put a value in your session. Click 'Contact' to see it.";
 
    return View();
}

From this point on, whenever you click to view the “About” page, a new value will be stored in session with the key “sessionkey”. If you switch over to Couchbase Console, you can see the data being stored.

Distributed session document in Couchbase

Note that a user’s session is represented by a single document. So, if I were to insert another session value (as below), that value would be stored in the same document.
HttpContext.Session.SetObject("sessionkey2", new
{
    Address = "123 Main St",
    City = "Lancaster",
    State = "OH"
});
1
2
3
4
5
6
	
HttpContext.Session.SetObject("sessionkey2", new
{
    Address = "123 Main St",
    City = "Lancaster",
    State = "OH"
});

The resultant document would look like:

Two distributed session keys

You should be careful not to go crazy with the amount of data you put into session, because Couchbase documents are limited to 20mb.
Reading from a distributed session

To get a value out of session, you can use GetObject and supply the session key. In the sample code, I did this in the Contact action:
public IActionResult Contact()
{
    ViewData["Message"] = HttpContext.Session.GetObject<dynamic>("sessionkey");

    return View();
}
1
2
3
4
5
6
	
public IActionResult Contact()
{
    ViewData["Message"] = HttpContext.Session.GetObject<dynamic>("sessionkey");
 
    return View();
}

After you visit the “About” page at least once, go to the “Contact” page. You should see the session object printed out to the page.

Output to ASP.NET from distributed session

That’s pretty much it. There are some other relatively self-evident methods available on Session. They are also outlined in the ASP.NET Core documentation.

One more thing: I named the cookie (“.MyApp.Cookie”). You can view this cookie in the browser of your choice. In Chrome, use Ctrl+Shift+I and navigate to the “Application” tab. You will see the cookie and its value.

Session cookie

You generally don’t need to know this detail in your day-to-day as an ASP.NET Core developer, but it’s good to know how things work just in case.
Summary

The distributed session extension for Couchbase is another tool in your box for helping to scale your ASP.NET Core applications. These handy .NET extensions help to demonstrate how Couchbase is the engagement database platform that you need.

If you have questions or comments on Couchbase Extensions, make sure to check out the GitHub repository or the Couchbase .NET SDK forums.

And please reach out to me with questions on all things .NET and Couchbase by leaving a comment below or finding me on Twitter @mgroves.

    Posted in: .NET, Couchbase Server	Tagged in: .NET, .NET Core, ASP.NET, ASP.NET Core, caching, couchbase, Couchbase Server, distributed session, extensions, session	


https://www.slideshare.net/Couchbase/getting-started-developing-with-couchbase


As part of a project I’m working on, I have a requirement for a NoSQL database. There are numerous offerings out there, of which MongoDB and CouchDB appear to be the most popular. So which system should I choose?

First, a little more information about my use case. I am part of a team who will be sending a balloon up into near-space (if you’re interested, you can find out about us on our Wordpress page). As it is in flight, the balloon will be sending telemetry information via radio back down to a ground station. Once we receive the data at the ground station, we store it in a database of some kind. The decoded data is not going to be particularly relational, hence a NoSQL database seems like a good storage method. The data will be handled as Javascript objects so either MongoDB or CouchDB seem to be a fairly good fit, given that they work by storing JSON documents.
The CAP triangle

A few years ago, Nathan Hurst wrote a blog post giving a visual guide to NoSQL systems. That post included the image below.

As you can see, there are three primary concerns you must balance when choosing a data management system: consistency, availability, and partition tolerance. * Consistency means that each client always has the same view of the data. * Availability means that all clients can always read and write. * Partition tolerance means that the system works well across physical network partitions.

As you can see in the diagram, MongoDB and CouchDB are built with a slightly different focus. Both scale across multiple nodes easily, but MongoDB favours consistency while CouchDB favours availability. In the MongoDB replication model, a group of database nodes host the same data set and are defined as a replica set. One of the nodes in the set will act as primary and the others will be secondary nodes. The primary node is used for all write operations, and by default all read operations as well. This means that replica sets provide strict consistency. Replication is used to provide redundancy - to recover from hardware failure or service interruptions. For more information, I would look at the Replication section of the MongoDB documentation.

CouchDB uses a replication model called Eventual Consistency. In this system, clients can write data to one node of the database without waiting for other nodes to come into agreement. The system incrementally copies document changes between nodes, meaning that they will eventually be in sync. More information can be found on the Eventual Consistency page of the CouchDB documentation.

Which system you go for would normally be determined by the priorities of your project. If your app involves trading in financial data or online commerce, you might want to ensure that all clients have a consistent view of the data. In other applications, the high availability offered by CouchDB might be more important, even if some clients are seeing data which is slightly out of date.

My use case is likely to only involve a single database node and I’m not expecting particularly high database traffic. With these relatively flexible constraints, I would expect that either MongoDB or CouchDB would be able to meet my use case without any problems. In the rest of this post I’ll look at how easy both systems were to use and I’ll make my decision based on that.
The data to be stored

The snippet below shows an example of the type of telemetry information which we’ll be storing.

{ payload_name: '$$icarus',
  sentence_id: '724',
  time: '12:19:07',
  latitude: '52.071851',
  longitude: '0.253108',
  altitude: '27539',
  speed: '36.11',
  heading: '113.8',
  temp_internal: '17.7',
  temp_external: '-18.7' }

We’ll be receiving data every few seconds. In this blog post, we’ll be running a database server locally and our client code will be running in Node.js. In the next couple of sections, we’ll look at how to store the data and how to make the kind of queries which we are likely to make on it. Let’s look at MongoDB first.
MongoDB

With MongoDB installed, the server can be started by calling mongod from the command line. Once running, we’re in a position to add data and make queries. In this post, two separate Node.js processes are used; one to insert new data into the database when it becomes available, and the other to make queries on the database.

To use MongoDB directly from Javascript rather than using the Mongo shell, we could either use the official MongoDB Node.js driver or we could use an Object Document Mapper (ODM). Mongoose is the officially supported ODM for Node.js, so it is what I have used for this work.

Mongoose requires you to define a schema for your data. This is actually a departure from vanilla MongoDB, which doesn’t require data in a collection to have a common schema. This will match our use case though, so it’s no big deal here. I’ve created a module which defines the schema we’ll be using and called it telemetryDb.js.

'use strict';

var mongoose = require('mongoose');

module.exports = {
    url: 'mongodb://localhost/telemetryDb',
    telemetrySchema: function() {
        return new mongoose.Schema({
            payload_name: String, 
            sentence_id: String, 
            time: String,
            latitude: Number,
            longitude: Number,
            altitude: Number,
            speed: Number,
            heading: Number,
            temp_internal: Number,
            temp_external: Number
        });
    },
    telemetryModelClass: function() {
        return mongoose.model('TelemetryInfo', this.telemetrySchema());
    }
};

As well as defining the schema, we declare the URL to the database and a model class which is based on the schema. Mongoose uses this model to create new documents and to query the database.
Writing to the database

Now let’s add documents to the database when new telemetry data is received. In our Node app which is receiving the telemetry data, let’s add a dependency on Mongoose and our schema module.

var mongoose = require('mongoose');
var telemetryDb = require('./telemetryDb');

We can now create and open a connection to the database. We declare the model class as well - we’ll use that to create new telemetry documents later on.

var db = mongoose.connection;
mongoose.connect(telemetryDb.url);

db.on('error', console.error);
db.once('open', function() {
});

var TelemetryDbModel = telemetryDb.telemetryModelClass();

Now, every time we receive new telemetry information, we can write it to the database.

// telemetryInfo is the Javascript object containing our new data.
// We create a Mongoose model object from it, then save that to 
// the database
var dbTelemetryInfo = new TelemetryDbModel(telemetryInfo);
dbTelemetryInfo.save(function(err, dbTelemetryInfo) {
  if (err) {
      return console.error(err);
  }
  // We log to the console, just to show what we've saved
  console.log(dbTelemetryInfo);
});

Querying the database

In a separate process, we’ll query the data. In a real-world app we’d probably want to see a snapshot of the latest data, and we might want to display a graph of historical data, such as altitude over time. Let’s write some queries to get this information. First, let’s create and open a connection to the database.

'use strict';

var mongoose = require('mongoose');
var telemetryDb = require('./telemetryDb');

var db = mongoose.connection;
mongoose.connect(telemetryDb.url);

db.on('error', console.error);
db.once('open', function() {
});

var TelemetryDbModel = telemetryDb.telemetryModelClass();

Now let’s write our queries. First we’ll want to get the latest data value. MongoDB provides a rich query interface which allows you to specify query criteria, projections, sort orders and limits. Mongoose provides a nice interface on top of this, which allows you to build up a query via their QueryBuilder interface.

TelemetryDbModel
.find()
.sort('-time')
.limit(1)
.exec(function(err, data) {
    if (err) return console.error(err);
    console.log(data);
});

As you can see, we used the Mongoose model class we created earlier to build up our query on the data. We specify that we want to sort data in descending time, and we’re only interested in the first result (the one with the latest time). Once the query has executed, we log it to the console. As well as the latest snapshot of the data, let’s get the historical altitude values. In this case, we sort the data into ascending chronological order and select just the time and altitude fields.

TelemetryDbModel
.find()
.sort('time')
.select('time altitude')
.exec(function(err, data) {
    if (err) return console.error(err);
    console.log(data);
});

Great, so now we have a system where we’re saving telemetry information to the database when we receive it, and we’re able to query it in order to display the information. I like the query interface that MongoDB offers, and the QueryBuilder interface which Mongoose builds on top of this also seems very powerful. Now that we have a working system with MongoDB, let’s take a look at how to implement the same functionality in CouchDB.
CouchDB

As with MongoDB, the first thing to do is to get a database server up and running. I’m running on a Mac and this is simple in that environment. I haven’t tried this on a Windows machine, but I imagine it would be similar there. On a Mac, you just download a zipped version of the CouchDB app, then unzip it and copy it to the Applications folder on your machine. After doing that, you can launch the app using Launchpad, and it will start the database server and open up Futon, its web-based administration panel. Futon will look a little like the screenshot below.

Futon gives you a button to create a new database. As you can see, I’ve used that to create a new database for our data, called telemetry. Now that we have a database, it’s time to populate it when we receive new telemetry information.
Writing to the database

CouchDB uses HTTP requests to populate or query the database, so we could just write HTTP PUT requests to do this. I’m going to simplify things even further though by using a 3rd party module to help. There are a few available but I’ve gone for Cradle in this example as it seems to be popular and offers an easy-to-use API. In the Node app where we receive telemetry information, we’ll add functionality to write any new data to CouchDB. At the top of the app, add a dependency on Cradle and create a connection to the database.

var cradle = require('cradle');

var db = new(cradle.Connection)().database('telemetry');

Now, whenever we receive new data, let’s write it to the database.

db.save(telemetryInfo, function(err, res) {
    if (err) {
        console.error(err);
    }
    console.log(res);
});

Cool, that was easy to do. Now let’s write some code to query the database once we’ve populated it.
Querying the database

To query the database in CouchDB you need to define a MapReduce function. These functions are declared as views within a design on the database. I’ve written some code below which will create views for the common types of queries which we will need. This code should be run once against the database to define the views. Once they are defined, we can query the database for the results of a particular view at any time.

'use strict';

var cradle = require('cradle');

var db = new(cradle.Connection)().database('telemetry');

db.save('_design/telemetryViews', {
      all: {
        map: function (doc) {
            emit(doc.time, doc);
        }
      },
      altitude: {
        map: function (doc) {
            emit(doc.time, doc.altitude);
        }
      }
  });

As you can see, I’ve defined two views on the database - one which returns all data and one which just returns altitude data. The results of each map function are sorted by their keys, which in this case are the times of the data.

Now that we’ve defined some views on our data, let’s use them to query the data we’ve received. We make one query to get a snapshot of the latest data, and another to get the historical altitude data which has been received from the balloon.

'use strict';

var cradle = require('cradle');

var db = new(cradle.Connection)().database('telemetry');

db.view('telemetryViews/all', {descending: true, limit: 1}, 
  function(err, res) {
    console.log('Get latest:');
    res.forEach(function(key, row, id) {
        console.log('%s: %s %s %s', key, row.altitude, row.latitude, 
          row.longitude);
    });
});

db.view('telemetryViews/altitude', function(err, res) {
    console.log('Altitude data:');
    res.forEach(function(key, row, id) {
        console.log('%s: %s', key, row);
    });
});

Conclusions

So, I hope you’ve found this blog post informative. Although my use case wasn’t pushing the performance boundaries of either system, I found it interesting learning how to use both. I was impressed by how easy it was to implement the functionality I wanted.

I found I slightly preferred using MongoDB due to its SQL-like querying syntax, but that could just be due to the fact that I’m more used to querying in that way rather than using MapReduce. I still found CouchDB a good system to work with.

If you need dynamic queries MongoDB will be the better option, as CouchDB requires you to define your views up front. Mongoose introduces the constraint that all the data in a collection must have the same schema. However this is a constraint introduced by Mongoose rather than MongoDB itself, and you could always use an alternative ODM or the MongoDB Node.js driver instead. I stuck with Mongoose as I liked the interface it offered for building queries.

If you have any questions, thoughts or feedback on this post, let me know! The full source code is up on my GitHub page, as part of the Project Latex project: https://github.com/DanGorst/project-latex

Whether your database needs to run on a mobile device or scale to a humongous size, this post has you covered with CouchDB vs. MongoDB. One of these databases can run on your phone while the other is prepared for serious growth; which one do you need?

 Who Uses These Databases?

Here are a few examples of companies that use these databases:

CouchDB: Talend SA, Akamai Technologies, Hothead Games, Inc., GenCorp Technologies, Vivint Solar, Inc.

MongoDB: Adobe, BBVA, CERN, Department of Veteran Affairs, Electronic Arts, Forbes, Under Armour
 
What About Database Structure?

CouchDB: CouchDB uses a document store with data being presented in the JSON format. It offers a RESTful HTTP API for reading, adding, editing, and deleting database documents. Each document consists of fields and attachments. Fields can consist of numbers, text, booleans, lists, and more.

The update model for CouchDB is optimistic and lockless. This database structure, inspired by Lotus Notes, can be scaled from global clusters down to mobile devices.

MongoDB: MongoDB stores schema-free data using documents in the BSON format. These collections of documents are not required to have a predefined structure, and columns can vary for different documents in the collection.

MongoDB is schema-free, allowing you to create documents without having to first create the structure for that document. At the same time, it still has many of the features of a relational database, including strong consistency and an expressive query language.

Are Indexes Needed?

CouchDB: Views in CouchDB are similar to indexes in SQL. Views in CouchDB can be used for filtering documents, retrieving data in a specific order, and creating efficient indexes so you can find documents using values within them. Once you have indexes, they can represent relationships between the documents. These view results are stored in a B-tree index structure.

CouchDB uses MapReduce, a two-step process that looks at all of the documents and creates a map result consisting of an ordered list of key/value pairs. The mapping occurs once after a document is created. After that, it is not changed unless the document is updated.

MongoDB: Indexes are the preferred method in MongoDB, and not having indexes can slow down read times.

See the trends driving data warehousing today

 
How Are Their Queries Different?

To view all documents in a database called mybooks:

CouchDB:

cURL can be used to query the database using HTTP:

curl -X GET http://127.0.0.1:5984/mybooks/_all_docs

MongoDB: db.mybooks.find( {} )

While selecting all documents is helpful, you often need to filter the result. In this case, we are going to search the database mybooks to find one with the search term “Tolstoy.”

CouchDB:

In order to look this up, we first need an index. CouchDB uses a map result to store the index.

To find the value “Tolstoy,” we need to retrieve the values in the key of a view. To do this, we use a map function:

function(doc) {

if(doc.author) {

emit(doc.author, null);

}

}

This map function will create a list of documents sorted by the author field.

To list all records that have the author “Tolstoy,” we use the following query:

curl -X GET http://127.0.0.1:5984/mybooks/_design/application/_view/author?key="Tolstoy"

MongoDB:

db.mybooks.find( { author: “Tolstoy” } )
Where (And How) Are These Databases Deployed?

CouchDB: CouchDB was written in Erlang and is available for Android, BSD, iOS, Linux, OS X, Solaris, and Windows.

It has support for many programming languages, including: C, C#, ColdFusion, Erlang, Haskell, Java, JavaScript, Lisp, Lua, Objective-C, OCaml, Perl, PHP, PL/SQL, Python, Ruby, and Smalltalk.

MongoDB: MongoDB was written in C++ and can be deployed to Linux, OS X, Solaris, and Windows.

The following programming languages are supported in MongoDB: Actionscript, C, C#, C++, Clojure, ColdFusion, D, Dart, Delphi, Erlang, Go, Groovy, Haskell, Java, JavaScript, Lisp, Lua, MatLab, Perl, PHP, PowerShell, Prolog, Python, R, Ruby, Scala, and Smalltalk.
What Types Of Replication / Clustering Are Available?

CouchDB: CouchDB supports both master-master and master-slave replication. This allows low latency access to data regardless of location. Replication in CouchDB is as simple as sending HTTP requests to the database with a source and target.

CouchDB will start sending any changes that occur in the source to the target database. This is a unidirectional process. If you want a bidirectional process, you will need to trigger the replication on the destination server with it being the source and the remote server being the destination.

MongoDB: MongoDB offers single-master replication with auto-election built-in. This will promote a secondary database (auto-election) if the primary database becomes unavailable. With replica sets in MongoDB, there can be one primary database with multiple replicated databases having the secondary role.

    With Panoply, you can connect to CouchDB and MongoDB databases at the same time. This allows you to access all of your data, regardless of where it is stored, from one place.

 

Who's Currently Behind The Databases?

CouchDB: CouchDB is currently managed by the Apache Software Foundation. It was originally created in 2005 by Damien Katz, a former IBM developer that worked on Lotus Notes.

MongoDB: MongoDB was started in 2007 by 10gen, which later changed its name to MongoDB, Inc. MongoDB, Inc. currently manages the project.
Who Provides Support?

CouchDB: The Apache Software Foundation offers community support at Slack and Freenode IRC network chat. Enterprise level support for the product is offered through professional services from companies like Neighbourhoodie Software.

MongoDB: MongoDB, Inc offers a support community via the Community Support Forum, ServerFault, and StackOverflow. Users can also get enterprise support 24x7 with optional lifecycle via Enterprise grade support.
Who Maintains The Documentation?

CouchDB: The documentation for CouchDB is maintained by the Apache Software Foundation and can be found at http://docs.couchdb.org/en/2.0.0/.

MongoDB: MongoDB, Inc. maintains the documentation for MongoDB and it can be found at https://docs.MongoDB.com/.
Is There An Active Community?

CouchDB: According to the CouchDB website, their primary goal is to “build a welcoming, supporting, inclusive and diverse community.” On the website, they offer a variety of ways people can contribute.

MongoDB: MongoDB offers an active community, which can be found at https://www.mongodb.com/community, where they offer information about events, webinars, user groups, and MongoDB University.
CouchDB vs MongoDB. Which Database Is Right For Your Business?

 
CouchDB vs MongoDB

 
CouchDB:

Mobile support: CouchDB stands out, in that it can run on an Android or iOS mobile device. In addition to being mobile, the database can also synchronize with a remote master database, allowing the data to be shared easily between mobile devices and servers.

Snapshots: Any changes to a document occur as a revision and appends the information to the file. This means you can grab a “snapshot” of the file and copy it to another location even while the database is running without having issues with corruption.

Replication: With CouchDB, you have master-master in addition to master-slave replication. Because CouchDB only does append-only modifications to the database, it lowers the risk of conflicts. With CouchDB, you can have master-master replication where all servers are bidirectionally replicating.

You also have the ability to do selective replication where filters can control which documents will be copied onto a device. This allows a mobile device with less memory to have a subset of a database.

Queries: In CouchDB, queries use map-reduce functions which can be a difficult concept to master for people with an SQL background. However, given time you may find it a quick and elegant solution.
MongoDB:

Queries: MongoDB is closer to SQL, and as a result will probably be easier for users with SQL experience to get up to speed.

Faster reads: MongoDB provides faster reads than CouchDB as MongoDB uses a binary protocol that is faster than CouchDB’s RESTful HTTP API method.

Replication: MongoDB only offers master-slave replication across replication sets. “If you need multiple masters in a Mongo environment, you have to setup sharding in addition to replica sets and each shard will be its own replica set with the ability to write to each master in each set. Unfortunately this leads to much more complex setups and you cannot have every server have a full copy of the data set (which can be handy/critical for some geographically dispersed systems - like a CDN or DNS service),” says Riyad Kalla, Director of Global Credit Platform at PayPal.

Size: If you need to store a large or rapidly growing dataset, then MongoDB is a better choice.

With Panoply, it doesn’t matter whether you pick CouchDB or MongoDB to run your business. With it, you get a single data management solution that can connect to cloud, CouchDB, MongoDB, Redis, Cassandra etc. without a single line of code.

Want to know more about MongoDB? Check our other comparisons: MongoDB vs Redis; MongoDB vs Cassandra or MongoDB vs MySQL.

In February 2011, CouchOne and Membase merged. The combined company is called Couchbase. Membase had a product called Membase which was a key/value, persistent, scalable solution that used the memcached wire protocol. CouchOne supported CouchDB. CouchDB is a document database which has a peer to peer replication approach, which is really good for mobile and geographically separated data centers. Couchbase created a new product combining parts of Membase and parts of CouchDB, and the new product is called Couchbase.

Recently Couchbase published a comparison of Couchbase and CouchDB to denote the differences and simlarities between the two. This document addresses a common question: "What is the difference between CouchDB and Couchbase?"

The reality is that Couchbase and CouchDB are closely related. The Couchbase product contains a copy of CouchDB. Couchbase product adds to CouchDB caching, clustering and more. InfoQ caught up with one of the founders of Couchbase, James Phillips to discuss the comparison and the merger of the two products Membase and CouchDB.

InfoQ: Membase seems to be a very solid brand, why did you change the product name to Couchbase?

    In early 2011, the company that was Membase merged with a company called CouchOne. The combined entity took a portion of each companies name – giving us Couchbase. Ultimately the name change better reflects the technology we offer – Couchbase is a document-oriented database (with technology inherited from the Apache CouchDB project) that can scale horizontally and which provides very low-latency access to data for both reads and writes (due to Membase technology).

InfoQ: Before selecting CouchDB as the persistence and query engine, what did Membase use?

    SQLite was the embedded storage engine used in Membase that was replaced by Apache CouchDB technology in Couchbase Server.

InfoQ: How important was the memcached wire protocol to Membase adoption?

    Memcached compatibility has been very important to the adoption of Membase and now Couchbase Server (which supports the same wire protocol). Every language and application development framework natively supports memcached, and most developers have used memcached previously, so it is easy to pick up and begin using.

InfoQ: Membase seemed like a very useful solution as it was, and certainly had some really big name customers and case studies like Zynga. What did you get by using CouchDB as the persistence/query layer that Membase customers were clamoring for?

    Couchbase is typically used as the system of record for interactive software systems – replacing the role previously played by relational database technology like MySQL or Oracle. The key-value operations that were supported by Membase certainly allowed useful systems to be built, but a simple key-value store can’t answer even simple questions such as “which users currently have a sheep on their farm?” In order to answer that question on a pure key-value store, the application must read the entire database, key by key, then “look inside” the value part of the key-value pair to see if there is a sheep inside. By embedding CouchDB, the database can now do that work on behalf of the application and without the need for a full database scan (because CouchDB can maintain an index that speeds that kind of query). 

InfoQ: Who is your closest competitor in the NoSQL, distributed data space?

    MongoDB. 

InfoQ: CouchBase and MongoDB are document oriented and are quite successful? What advantages does a document oriented approach have over column oriented approach like Cassandra (BigTable/Dynamo hybrid)?

    With a document oriented database an application can insert records (“documents”) without regard to their structure, as long as they adhere to some standard formatting rules (e.g. XML, JSON). Queries can then be executed regardless of whether certain columns have been defined, or column families or super columns or any of the other structures that a column-oriented database requires one to maintain. The document-oriented model provides a more flexible, general-purpose approach to transactional data management without limiting the kinds of queries that can be run. 

InfoQ: The Couchdb/Couchbase comparison mentions couchbase adds autosharding capabilities to CouchDB. Does Couchbase add any additional support for replication for high availability above and beyond what core CouchDB offers?

    Couchbase Server actually includes two kinds of “replication” technology: For intra-datacenter deployments (a cluster), Membase-style replication (which favors immediate consistency in the face of a network partition) is used as it provides the most natural development model and the likelihood of a split-brain network partition can be engineered to be statistically less probable than an asteroid collision with the data center. For inter-datacenter deployments (where clusters are geographically distributed) the likelihood of a split-brain network partition is very high, since application servers AND database servers live on both sides of a (relatively) fragile WAN connection. CouchDB-style replication is used in cross-datacenter deployments as it supports conflict detection and resolution which is more likely in this scenario. 

InfoQ: Couchbase like Membase before it is a drop in replacement for Memcached so application using Memcached can use Couchbase right out of the gate, but how do client drivers not written with auto-sharding in mind utilize Couchbase's autosharding features?

    There is a proxy-layer (called moxi), built-in to Couchbase Server, or deployable on the application server, that bridges the gap between the consistent hashing algorithm approach used by “off the shelf” memcached clients and the 2 level indirection employed by Couchbase Server (hashing to find virtual server, then lookup to map virtual to real server). 

InfoQ: How does Couchbase address applications that need reliable persistence? Is their a journaling option? Is their an option where the data has to be replicated to more nodes? How do you balance write speed with reliable persistence? Do you need to have at least two servers for some guarantee of durability?

    Couchbase can be configured (on a per operation basis) to acknowledge writes immediately (with writing done asynchronously) or only after data has been replicated or written to durable media. Users get to make their own durability and performance trade-offs. 

Background on Membase, Couchbase and Northscale

Membase (the product) was announced October 2010, and was developed by Zynga, and NorthScale, and NHN. NorthScale became Membase Inc., which then became Couchbase Inc. after merging with CouchOne Inc in 2011. Membase is used by Zynga for its popular social games, namely, Farmville, Mafia Wars, and Cafe World. Membase was optimized for storing web applications data like Farmville's data. These online social games store a lot of data. "It's a mind-boggling amount of data. It's a new sort of data, and it warranted development of a new sort of database management system (Membase)" according to Audrey Watters of ReadWrite Cloud. Zynga was already using Memcached so the transition to Membase was a natural one. There was an InfoQ interview with Dustin Sallings, a Couchbase engineer, who discused changes to Memcached wire protocol to support Membase like products.

In a related InfoQ story Damien Katz, creator of CouchDB and another co-founder of Couchbase, announced he was going to focus on Couchbase as this was an opportunity to start-over with CouchDB and throw out what did not work, strengthen what was working, and include the scalability, speed, clustering, and caching features of Membase in the combined Couchbase product. Damien lamented on the speed and progress of a consensus based Apache project, and the need for a successful comercial product to move quickly. His take on merging the products was to create a combined product that played on both of their strengths. In a follow up blog post, Damien went on to say Membase product is very fast and scalable, but has no reporting capability or cross-datacenter replication capability. CouchDB product has more features like advanced replication and reporting, but is not fast, and can’t keep up with high loads. The combination of the two should be a very successful combination, and Couchbase was born.




The new “hotness” in the Microsoft .NET world is .NET Core Framework: an open source, cross platform (OSX, Linux, and Windows) implementation of the .NET framework. In an effort to provide the very best developer environment, today Couchbase is releasing a .NET Core compatible SDK! This initial version is a developer preview, and actually supports .NET Framework 4.5 and .NET Core 1.0. More on that later.
What's in this package?

If your following the Couchbase .NET SDK, you'll notice that we bumped the minor version from 2.3.X to 2.4.X in this release. The reason is that final GA version of 2.4.0 will contain several new features which broaden this public facing API of the SDK:

    Cluster Level Authentication
    Data structures API
    Cluster level query
    Generic “find”

These features are either in development or about to begin development and will make their way into subsequent DP's – this release, DP1, only includes .NET Core compatibility.

Importantly note that this package includes both .NET Framework 4.5 (our base .NET version that the SDK supports) and .NET Core 1.0 (via NetStandard1.5). Your target project type will determine which version of the SDK is used. It also means that the NuGet package will be backwards compatible with your existing code as long as you do not convert your projects to .NET Core projects.

Additionally, there is a high probability that the SDK will not support synchronous methods for the final .NET Core version; this is because Microsoft has been moving away from the older synchronous API's to async everything. You'll still be able to call the async methods synchronously via Task.Result, we just won't offer a pure synchronous version.
Getting Started on Linux

In the following section I will show how to use the Couchbase .NET Core 2.4.0-dp1 in a simple console application running on Ubuntu 14.0.4. I am assuming that you have already installed .NET Core 1.0.1 on the machine, if you haven't please follow these directions. It also assumes you have installed Couchbase Server 4.5. If you haven't please download and install it.

First open, a terminal and make a directory called cb-core-example and then change to that directory and run dotnet new:

Using VIM or your favorite editor, open up the project.json file that was created when you ran dotnet new. Add the dependency to the CouchbaseNetClient package on NuGet get, specifying the correct version (2.4.0-dp1):

Again using VIM or your favorite editor, open up the Program.cs file and enter the following code:

Once you have done this, you'll just do a dotnet restore and dotnet run to update the dependencies and run the application. If everything works out, you should see the words SUCCESS written to the terminal.

Once again, the commands are as follows:

mkdir cb-core-example1
cd cb-core-example1
dotnet new
vim project.json
vim Program.cs
dotnet restore
dotnet run
1
2
3
4
5
6
7
	
mkdir cb-core-example1
cd cb-core-example1
dotnet new
vim project.json
vim Program.cs
dotnet restore
dotnet run

Community Shout Outs

This developer preview was months in the making and included several contributions from the community. A big shout out to Brant Burnett of CenterEdge Software for making core contributions and guidance with packaging and API migrations to Core supported libraries.
Contributing and reporting bugs

The Couchbase .NET SDK is always looking for community contributions and feedback. If you would wish to contribute, the Github repo is here. If you find a bug, create a Jira ticket or do a forums post.
How to get it?

    Install the NuGet package.
    Clone the Github repo
    Download the binaries




https://www.google.co.in/imgres?imgurl=https%3A%2F%2Fblog.couchbase.com%2Fwp-content%2Foriginal-assets%2F2016%2Foctober%2Fintroducing-couchbase-.net-sdk-core-2.4.0-dp1%2Fcode-listing.png&imgrefurl=https%3A%2F%2Fblog.couchbase.com%2Fintroducing-couchbase-net-sdk-core-2-4-0-dp1%2F&docid=W4NmkjsMXnlZZM&tbnid=kgOFT0ihLuFwDM%3A&vet=10ahUKEwj3kOLVvbjYAhXGNo8KHVxvBUwQMwhJKAwwDA..i&w=722&h=606&bih=656&biw=1366&q=couchbase%20using%20.net%20core%20architecture&ved=0ahUKEwj3kOLVvbjYAhXGNo8KHVxvBUwQMwhJKAwwDA&iact=mrc&uact=8


